<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Voice Assistant ‚Äî Day 12</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: Arial, sans-serif;
      background: linear-gradient(to right, #0f2027, #203a43, #2c5364);
      color: #fff;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
    }

    .container {
      background-color: #1c2b38;
      padding: 30px;
      border-radius: 20px;
      box-shadow: 0 8px 16px rgba(0, 0, 0, 0.5);
      text-align: center;
      width: 520px;
    }

    h1 {
      color: #42caff;
      margin-bottom: 20px;
    }

    #recordBtn {
      background-color: #ff4d4d;
      color: white;
      border: none;
      border-radius: 50%;
      padding: 30px 40px;
      font-size: 20px;
      cursor: pointer;
      outline: none;
      transition: transform 0.2s ease, background-color 0.3s ease;
    }

    #recordBtn:hover {
      background-color: #e63939;
      transform: scale(1.05);
    }

    #recordBtn.recording {
      animation: pulse 1.2s infinite;
      background-color: #d93636;
    }

    @keyframes pulse {
      0% {
        transform: scale(1);
      }
      50% {
        transform: scale(1.15);
      }
      100% {
        transform: scale(1);
      }
    }

    .upload-status {
      color: limegreen;
      margin-top: 10px;
      font-size: 0.9em;
    }

    .transcription {
      color: #fff;
      background-color: #2c5364;
      border-radius: 10px;
      padding: 10px;
      margin-top: 20px;
      font-size: 0.95em;
      word-break: break-word;
      display: none;
    }

    audio {
      display: none;
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>Conversational Agent</h1>
    <button id="recordBtn">üé§ Start Recording</button>
    <div class="upload-status" id="uploadStatus"></div>
    <audio id="audioPlayer" autoplay></audio>
    <div class="transcription" id="transcriptionBox"></div>
  </div>

  <script>
    // === Session ID handling ===
    function getSessionId() {
      const params = new URLSearchParams(window.location.search);
      let sid = params.get("session_id");
      if (!sid) {
        sid = Math.random().toString(36).substring(2, 10);
        params.set("session_id", sid);
        window.history.replaceState({}, "", `${location.pathname}?${params}`);
      }
      return sid;
    }
    const sessionId = getSessionId();

    let mediaRecorder;
    let audioChunks = [];
    let recordingMime = "audio/webm";
    let isRecording = false;

    const SERVER_BASE = "http://127.0.0.1:8000";
    const SERVER_ENDPOINT = `${SERVER_BASE}/agent/chat/${sessionId}`;

    const recordBtn = document.getElementById("recordBtn");
    const audioPlayer = document.getElementById("audioPlayer");

    recordBtn.addEventListener("click", () => {
      if (!isRecording) {
        startRecording();
      } else {
        stopRecording();
      }
    });

    function playFallbackAudio() {
      audioPlayer.src = "fallback.wav";
      audioPlayer.play().catch(err => console.error("Could not play fallback audio:", err));
      document.getElementById("uploadStatus").innerText = "‚ö† Using fallback audio";
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.addEventListener("dataavailable", event => {
          if (event.data && event.data.size > 0) {
            audioChunks.push(event.data);
          }
        });

        mediaRecorder.addEventListener("start", () => {
          isRecording = true;
          recordBtn.textContent = "‚èπ Stop Recording";
          recordBtn.classList.add("recording");
          document.getElementById("uploadStatus").innerText = "Recording...";
          document.getElementById("transcriptionBox").style.display = "none";
        });

        mediaRecorder.addEventListener("stop", async () => {
          isRecording = false;
          recordBtn.textContent = "üé§ Start Recording";
          recordBtn.classList.remove("recording");

          const audioBlob = new Blob(audioChunks, { type: recordingMime });

          document.getElementById("uploadStatus").innerHTML =
            "‚úÖ Recorded locally ‚Äî size: " + (audioBlob.size / 1024).toFixed(2) + " KB";

          try {
            await uploadAndTranscribe(audioBlob);
          } catch (err) {
            console.error("Error in upload & transcribe:", err);
            playFallbackAudio();
          }
        });

        mediaRecorder.start();
      } catch (err) {
        console.error("Mic access error:", err);
        playFallbackAudio();
      }
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
      }
    }

    async function uploadAndTranscribe(audioBlob) {
      const formData = new FormData();
      formData.append("file", audioBlob, "recording.webm");

      document.getElementById("uploadStatus").innerText = "Uploading & processing chat...";

      try {
        const resp = await fetch(SERVER_ENDPOINT, {
          method: "POST",
          body: formData
        });

        if (!resp.ok) {
          throw new Error(`Server error ${resp.status}`);
        }

        const data = await resp.json();
        const transcriptionBox = document.getElementById("transcriptionBox");
        transcriptionBox.innerHTML =
          `üìù Transcription:<br>${data.user_message || "No text"}<br><br>` +
          `ü§ñ LLM Response:<br>${data.assistant_message || "No response"}`;
        transcriptionBox.style.display = "block";

        if (data.audio_url) {
          let audioSrc = data.audio_url;
          if (audioSrc.startsWith("/")) {
            audioSrc = SERVER_BASE + audioSrc;
          }
          audioPlayer.src = audioSrc;

          audioPlayer.onended = () => {
            console.log("LLM response finished ‚Äî ready for next recording...");
          };

          await audioPlayer.play().catch(e => console.info("Autoplay blocked", e));

          document.getElementById("uploadStatus").innerText = "‚úÖ Murf audio ready";
        } else {
          document.getElementById("uploadStatus").innerText = "‚ùå No audio from server";
          playFallbackAudio();
        }
      } catch (err) {
        console.error("Chat error:", err);
        document.getElementById("transcriptionBox").innerHTML = "‚ùå Error: " + err.message;
        document.getElementById("transcriptionBox").style.display = "block";
        document.getElementById("uploadStatus").innerText = "‚ùå Error in chat process";
        playFallbackAudio();
      }
    }
  </script>
</body>
</html>
